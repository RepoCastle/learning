# Advanced Spark Programming

## Introduction

 - **accumulators** to aggregate information.
 - **broadcast variables** to efficiently distribute large values.
 - **batch operations** for tasks with high setup costs (share setup work across multiple data items)
 - Spark's methods for **interacting with external programs** (with `pipe()`)

## Accumulators

 **Accumulator** provides a simple syntax for **aggregating values** from **worker nodes** back to the **driver program**.

 **`sc.accumulator(initialValue)`** in the driver, initialValue could be in the type of (**Int**, **Double**, **Long**, **Float**), out of the box.

 Tasks on **worker nodes** **CANNOT access** the accumulator's **`value()`**.

 The value of accumulators is **available only in the driver program**, so that is where we place the checks.

### Accumulators and Fault Tolerance

 The same function may run multiple times on the same data depending on what happens on the cluster.
 While for accumulators used in actions, Spark applies each task's update to each accumulator only once.

  Thus, if we want a reliable absolute value counter, regardless of failures or multiple evaluations, we **must put it inside an action** like `foreach()`.

### Custom Accumulators

 **AccumulatorParam**

 operation should be **commutative** and **associative**. (Monoid ???)


## Broadcast Variables

  A broadcast variable is simply an object of type **`spark.broadcast.Broadcast[T]`**.

  > Spark will send same variable in multiple parallel operations separately for each operation.

  Used for sending a **large, read-only value** to **all the worker nodes**.

  **Broadcast variable** value is sent to each node **only once**, using an efficient, **BitTorrent-like** communication mechanism.

### Optimizing Broadcasts

  Choose a **data serialization format** that is both *fast* and *compact*.

  **`spark.serializer`** (e.g. Kryo)



## Working on a Per-Partition Basis

 Working with data on a per-partition basis allows us to avoid redoing setup work for each data item.

 Spark has per-partition versions of map and foreach to help reduce the cost of these operations by letting you run code **only once for each partition of an RDD**.

 - **`mapPartitions()`**: f: (Iterator[T]) -> Iterator[U]
 - **`mapPartitionsWithIndex()`**: f: (Int, Iterator[T]) -> Iterator[U]
 - **`foreachPartition()`**: f: (Iterator[T]) -> Unit


## Piping to External Programs





## Numeric RDD Operations

